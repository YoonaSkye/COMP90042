{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files\n",
    "import json\n",
    "documents_set = json.load(open('documents.json'))\n",
    "training_set = json.load(open('training.json'))\n",
    "devel_set = json.load(open('devel.json'))\n",
    "testing_set = json.load(open('testing.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1. Information Retrieval to find the best matching sentence </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from math import log\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"wordnet\") \n",
    "nltk.download('punkt')\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english')) \n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "lmtzr = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Preprocessing: lowercase, remove stopwords, stem the words and form words representation \n",
    "def preprocess(doc):\n",
    "    preprocessed_doc = []\n",
    "    doc = re.sub(r'[^\\w\\s]', '', doc) # remove punctuations\n",
    "    tokens = word_tokenize(doc)\n",
    "    for token in tokens:\n",
    "        if token.lower() not in stopwords: #remove stopwords\n",
    "            preprocessed_doc.append(stemmer.stem(token.lower())) # stem the word\n",
    "    return preprocessed_doc        \n",
    "\n",
    "\n",
    "# collect term frequencies for each sentence (a bag of words)\n",
    "def extract_term_freqs(sentence):\n",
    "    tfs = Counter()\n",
    "    preprocessed_sent = preprocess(sentence)\n",
    "    for token in preprocessed_sent:\n",
    "        tfs[token] += 1\n",
    "    return tfs\n",
    "\n",
    "\n",
    "# compute document frequencies(here refers to a term occurs in how many sentences within a document)\n",
    "def compute_doc_freqs(doc_term_freqs):\n",
    "    dfs = Counter()\n",
    "    for tfs in doc_term_freqs.values():\n",
    "        for term in tfs.keys():\n",
    "            dfs[term] += 1\n",
    "    return dfs\n",
    "\n",
    "\n",
    "# process documents_set into sentences\n",
    "def sent_tokenize(documents_set):\n",
    "    documents_set_sents = {}\n",
    "    for docid in range(len(documents_set)):\n",
    "        doc = documents_set[docid]['text']\n",
    "        sentences = []\n",
    "        for para in doc:\n",
    "            sentences += nltk.sent_tokenize(para)\n",
    "        documents_set_sents[docid] = sentences\n",
    "    return documents_set_sents\n",
    "documents_set_sents = sent_tokenize(documents_set)\n",
    "\n",
    "\n",
    "# process the document_set into term frequencies\n",
    "def get_term_frequencies(documents_set_sents):\n",
    "    doc_term_freqs = {}\n",
    "    for docid in range(len(documents_set_sents)):\n",
    "        doc = documents_set_sents[docid]\n",
    "        sent_term_freqs = {}\n",
    "        for sent_id in range(len(doc)):\n",
    "            term_freqs = extract_term_freqs(doc[sent_id])\n",
    "            sent_term_freqs[sent_id] = term_freqs\n",
    "        doc_term_freqs[docid] = sent_term_freqs\n",
    "    return doc_term_freqs\n",
    "doc_term_freqs = get_term_frequencies(documents_set_sents)\n",
    "\n",
    "\n",
    "# process the document_set into document frequencies\n",
    "def get_doc_freqs(doc_term_freqs):\n",
    "    doc_freqs = {}\n",
    "    for docid in doc_term_freqs.keys():\n",
    "        sent_freqs = compute_doc_freqs(doc_term_freqs[docid])\n",
    "        doc_freqs[docid] = sent_freqs\n",
    "    return doc_freqs\n",
    "doc_freqs = get_doc_freqs(doc_term_freqs)\n",
    "\n",
    "\n",
    "# build an inverted index to allow for efficient lookup by term\n",
    "def inverted_index(doc_term_freqs):\n",
    "    inverted_index_dict = {}\n",
    "    for docid in doc_term_freqs.keys():\n",
    "        inverted_index = defaultdict(list)\n",
    "        # note the inversion of the indexing, to be term -> (sent_id, tf)\n",
    "        for sent_id, term_freqs in doc_term_freqs[docid].items():\n",
    "            for term in term_freqs.keys():\n",
    "                inverted_index[term].append([sent_id, term_freqs[term]])\n",
    "        inverted_index_dict[docid] = inverted_index\n",
    "    return inverted_index_dict\n",
    "inverted_index_dict = inverted_index(doc_term_freqs)\n",
    "\n",
    "\n",
    "# Store the number of tokens in each sentence of a document\n",
    "def get_token_num(documents_set_sents):\n",
    "    token_num_dict = {}\n",
    "    for docid in range(len(documents_set_sents)):\n",
    "        sent_length_dict = {}\n",
    "        doc = documents_set_sents[docid]\n",
    "        for sent_id in range(len(doc)):\n",
    "            preprocessed_sent = preprocess(doc[sent_id])\n",
    "            sent_length_dict[sent_id] = len(preprocessed_sent)\n",
    "        token_num_dict[docid] = sent_length_dict\n",
    "    return token_num_dict\n",
    "token_num_dict = get_token_num(documents_set_sents)\n",
    "\n",
    "\n",
    "# store the number of sentences in a documents\n",
    "def get_sent_num(documents_set_sents):\n",
    "    sent_num = {}\n",
    "    for docid in range(len(documents_set_sents)):\n",
    "        sent_num[docid] = len(documents_set_sents[docid])\n",
    "    return sent_num\n",
    "sent_num = get_sent_num(documents_set_sents)\n",
    "\n",
    "\n",
    "# compute BM25\n",
    "def Okapi_BM25(query, docid, sent_num, inverted_index_dict, token_num_dict, doc_term_freqs, doc_freqs):\n",
    "    preprocessed_query = preprocess(query)\n",
    "    query_terms = set(preprocessed_query)\n",
    "    query_terms_freqs = extract_term_freqs(query)\n",
    "    k1 = 1.2\n",
    "    k3 = 1.5\n",
    "    b = 0.75\n",
    "    score = {}\n",
    "                \n",
    "    for sent_id in range(sent_num[docid]):\n",
    "        sent_score = 0\n",
    "        for term in query_terms:\n",
    "            N = sent_num[docid]                          # the number of sentences\n",
    "            f = len(inverted_index_dict[docid][term])    # number of sentences contain term\n",
    "            fdt =  doc_term_freqs[docid][sent_id][term]  # number of a term in a sentence\n",
    "            Ld = sum(doc_term_freqs[docid][sent_id].values())     # length of a sentence\n",
    "            Lavg =  sum(doc_freqs[docid].values()) / sent_num[docid]   # ave length of sentences\n",
    "            fqt = query_terms_freqs[term]                # number of term in a query\n",
    "\n",
    "            idf = log((N - f + 0.5)/(f + 0.5))\n",
    "            tf_doc = ((k1 + 1) * fdt)/(k1 * ((1-b) + b * Ld/Lavg) + fdt)\n",
    "            query_tf = (k3 + 1) * fqt / (k3 + fqt)\n",
    "            query_tf = (k3 + 1) * fqt / (k3 + fqt)\n",
    "            wt = idf * tf_doc * query_tf\n",
    "            sent_score += wt\n",
    "        score[sent_id] = sent_score\n",
    "    return score\n",
    "\n",
    "# return the best matching sentence\n",
    "def best_matching_sent_id(scores):\n",
    "    best_matching_sent_id = max(scores, key=lambda k: scores[k])\n",
    "    return best_matching_sent_id\n",
    "\n",
    "\n",
    "def best_match_sent(documents_set_sents, data_set):\n",
    "    best_match_sent = {}\n",
    "    for query_id in range(len(data_set)):\n",
    "        query = data_set[query_id]['question']\n",
    "        docid = data_set[query_id]['docid']\n",
    "        scores = Okapi_BM25(query, docid, sent_num, inverted_index_dict, token_num_dict, doc_term_freqs, doc_freqs)\n",
    "        best_matching_sent_id = max(scores, key=lambda k: scores[k])\n",
    "        best_match_sent[query_id] = documents_set_sents[docid][best_matching_sent_id]\n",
    "    return best_match_sent\n",
    "\n",
    "# generate best match sentence for questions in training set, development set and testing set.\n",
    "\n",
    "best_match_sent_devel = best_match_sent(documents_set_sents, data_set = devel_set)\n",
    "best_match_sent_test = best_match_sent(documents_set_sents, data_set = testing_set)\n",
    "best_match_sent_train = best_match_sent(documents_set_sents, data_set = training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2. Named Entity Recognition</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reference: Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating Non-local Information into Information Extraction Systems \n",
    "by Gibbs Sampling. Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics (ACL 2005), \n",
    "pp. 363-370. http://nlp.stanford.edu/~manning/papers/gibbscrf3.pdf\n",
    "'''\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk import pos_tag, sent_tokenize, word_tokenize\n",
    "from nltk.chunk import conlltags2tree\n",
    "from nltk.tree import Tree\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# StanfordNERTagger 7 class model for recognizing locations, persons, organizations, times, money, percents, and dates\n",
    "st = StanfordNERTagger('/Users/yue/stanford-ner/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "                       '/Users/yue/stanford-ner/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "\n",
    "\n",
    "# obtain stanford entity information for best match sentences\n",
    "def get_tagged_sents(best_match_sents):\n",
    "    sents_list = []\n",
    "    for i in range(len(best_match_sents.keys())):\n",
    "        sents_list.append(word_tokenize(best_match_sents[i]))\n",
    "    tagged_sent = st.tag_sents(sents_list)\n",
    "    for st_tag in tagged_sent:\n",
    "        for token, tag in st_tag:\n",
    "            if token == '': # remove empty array\n",
    "                st_tag.remove((token, tag))\n",
    "    return tagged_sent\n",
    "        \n",
    "st_best_match_sents_devel = get_tagged_sents(best_match_sent_devel)\n",
    "st_best_match_sents_test = get_tagged_sents(best_match_sent_test)\n",
    "st_best_match_sents_train = get_tagged_sents(best_match_sent_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Stanford NER Tagger result into NLTK tress\n",
    "## Adapted from https://stackoverflow.com/questions/30664677/extract-list-of-persons-and-organizations-using-stanford-ner-tagger-in-nltk\n",
    "\n",
    "from nltk.chunk import conlltags2tree\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# named entity boundaries\n",
    "def stanfordNE2bio(st_tag):\n",
    "    bio_tagged_sent = []\n",
    "    prev_tag = 'O'\n",
    "    for token, tag in st_tag:\n",
    "        if tag == \"O\": #O\n",
    "            bio_tagged_sent.append((token, tag))\n",
    "            prev_tag = tag\n",
    "            continue\n",
    "        if tag != \"O\" and prev_tag == \"O\": # Begin NE\n",
    "            bio_tagged_sent.append((token, \"B-\"+tag))\n",
    "            prev_tag = tag\n",
    "        elif prev_tag != \"O\" and prev_tag == tag: # Inside NE\n",
    "            bio_tagged_sent.append((token, \"I-\"+tag))\n",
    "            prev_tag = tag\n",
    "        elif prev_tag != \"O\" and prev_tag != tag: # Adjacent NE\n",
    "            bio_tagged_sent.append((token, \"B-\"+tag))\n",
    "            prev_tag = tag\n",
    "    return bio_tagged_sent\n",
    "\n",
    "\n",
    "# convert Stanford NER Tagger result into NLTK tress\n",
    "def stanfordNE2tree(st_tag):\n",
    "    bio_tagged_sent = stanfordNE2bio(st_tag)\n",
    "    sent_tokens, sent_ne_tags = zip(*bio_tagged_sent)\n",
    "    sent_pos_tags = [pos for token, pos in pos_tag(sent_tokens)]\n",
    "    sent_conlltags = [(token, pos, ne) for token, pos, ne in zip(sent_tokens, sent_pos_tags, sent_ne_tags)]\n",
    "    ne_tree = conlltags2tree(sent_conlltags)\n",
    "    return ne_tree\n",
    "\n",
    "\n",
    "# get continuous named entity words\n",
    "def get_continuous_NE(st_tag):\n",
    "    ne_tree = stanfordNE2tree(st_tag)\n",
    "    ne_in_sent = []\n",
    "    ne_token = []\n",
    "    for subtree in ne_tree:\n",
    "        if type(subtree) == Tree: \n",
    "            ne_label = subtree.label()\n",
    "            ne_string = \" \".join([token for token, pos in subtree.leaves()])\n",
    "            ne_in_sent.append((ne_string.lower(), ne_label))\n",
    "            ne_token.append(ne_string.lower())\n",
    "    return ne_in_sent\n",
    "\n",
    "## End of adaptation \n",
    "\n",
    "\n",
    "# obtain final named entity by joining contiguous words with the same type for each data set\n",
    "def get_final_en(st_best_match_sents):\n",
    "    final_en = []\n",
    "    for st_tag in st_best_match_sents:\n",
    "        final_en.append(get_continuous_NE(st_tag))\n",
    "    return final_en\n",
    "\n",
    "devel_set_ne = get_final_en(st_best_match_sents_devel)\n",
    "train_set_ne = get_final_en(st_best_match_sents_train)\n",
    "test_set_ne = get_final_en(st_best_match_sents_test)\n",
    "\n",
    "%store devel_set_ne\n",
    "%store train_set_ne\n",
    "%store test_set_ne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best sentence full tag: combine POS tag feature and Named Entity feature\n",
    "def get_continuous_NE_and_postag(st_tag):\n",
    "    ne_tree = stanfordNE2tree(st_tag)\n",
    "    ne_in_sent = []\n",
    "    ne_token = []\n",
    "    for subtree in ne_tree:\n",
    "        if type(subtree) == Tree: \n",
    "            ne_label = subtree.label()\n",
    "            ne_string = \" \".join([token for token, pos in subtree.leaves()])\n",
    "            ne_in_sent.append((ne_string.lower(), ne_label))\n",
    "            ne_token.append(ne_string.lower())\n",
    "        else:\n",
    "            ne_in_sent.append(subtree)\n",
    "    return ne_in_sent\n",
    "\n",
    "def get_final_en_and_postag(st_best_match_sents):\n",
    "    final_en_postag = []\n",
    "    for st_tag in st_best_match_sents:\n",
    "        final_en_postag.append(get_continuous_NE_and_postag(st_tag))\n",
    "    return final_en_postag\n",
    "\n",
    "devel_best_sent_ne_postag = get_final_en_and_postag(st_best_match_sents_devel)\n",
    "train_best_sent_ne_postag = get_final_en_and_postag(st_best_match_sents_train)\n",
    "test_best_sent_ne_postag = get_final_en_and_postag(st_best_match_sents_test)\n",
    "\n",
    "%store devel_best_sent_ne_postag\n",
    "%store train_best_sent_ne_postag\n",
    "%store test_best_sent_ne_postag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get POS tag for each token in each query\n",
    "def get_query_full_postag(dataset):\n",
    "    query_full_pos_tag = []\n",
    "    for query_id in range(len(dataset)):\n",
    "        query = word_tokenize(dataset[query_id]['question'].lower())\n",
    "        query_full_pos_tag.append(pos_tag(query))\n",
    "    return query_full_pos_tag\n",
    "\n",
    "train_query_full_postag = get_query_full_postag(training_set)\n",
    "devel_query_full_postag = get_query_full_postag(devel_set)\n",
    "test_query_full_postag = get_query_full_postag(testing_set)\n",
    "\n",
    "%store train_query_full_postag\n",
    "%store devel_query_full_postag\n",
    "%store test_query_full_postag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get named entity and POS tag for questions \n",
    "def get_queries(dataset):\n",
    "    query = {}\n",
    "    for query_id in range(len(dataset)):\n",
    "        query[query_id] = dataset[query_id]['question']\n",
    "    return query\n",
    "\n",
    "devel_queries = get_queries(devel_set)\n",
    "test_queries = get_queries(testing_set)\n",
    "train_queries = get_queries(training_set)\n",
    "st_devel_queries = get_tagged_sents(devel_queries)\n",
    "st_test_queries = get_tagged_sents(test_queries)\n",
    "st_train_queries = get_tagged_sents(train_queries)\n",
    "\n",
    "devel_query_ne_postag = get_final_en_and_postag(st_devel_queries)\n",
    "train_query_ne_postag = get_final_en_and_postag(st_train_queries)\n",
    "test_query_ne_postag = get_final_en_and_postag(st_test_queries)\n",
    "\n",
    "\n",
    "# named entity\n",
    "devel_query_ne = get_final_en(st_devel_queries)\n",
    "trian_query_ne = get_final_en(st_train_queries)\n",
    "test_query_ne = get_final_en(st_test_queries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 3. Question type classifier </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a question classifier\n",
    "'''\n",
    "Aknowlege:\n",
    "https://shirishkadam.com/2017/07/03/nlp-question-classification-using-support-vector-machines-spacyscikit-learnpandas/\n",
    "WH-word: The WH-word in a question holds a lot of information about the intent of the question and what basically it is trying to seek. (What, When, How, Where and so on)\n",
    "WH-word POS: The part of speech of the WH-word (wh-determiner, wh-pronoun, wh-adverb)\n",
    "POS of the word next to WH-word: The part of speech of the word adjacent to WH-word or the word at 1st position in the bigram (0th being the WH-word).\n",
    "head word: the first NP after the question’s wh-word.\n",
    "'''\n",
    "'''\n",
    "The question types:\n",
    "“person” (who/whom/whose)\n",
    "“date”/“time”(when)\n",
    "“location” (where), \n",
    "“entity: physical object”(what/which), \n",
    "“numeric value”/“Money” (how many/how much/how far/how long etc)\n",
    "“description” (how/why). \n",
    "wh_word_list = ['what', 'which', 'who', 'whom', 'whose', 'when', 'where', 'why', 'how']\n",
    "'''\n",
    "\n",
    "# tag the answers of training set \n",
    "def label_ans(dataset, ne_dict):\n",
    "    ans_type_dict = {}\n",
    "    for query_id in range(len(dataset)):\n",
    "        query = dataset[query_id]['question']\n",
    "        ans = [token for token, pos in ne_dict[query_id]]\n",
    "        pos = [pos for token, pos in ne_dict[query_id]]\n",
    "        if dataset[query_id]['text'] in ans:\n",
    "            index = ans.index(dataset[query_id]['text'])\n",
    "            ans_type_dict[query_id] = pos[index]\n",
    "        else:\n",
    "            ans_type_dict[query_id] = 'OTHER'\n",
    "    return ans_type_dict\n",
    "\n",
    "train_ans_labbled = label_ans(training_set, train_set_ne)\n",
    "devel_ans_labbled = label_ans(devel_set, devel_set_ne)\n",
    "\n",
    "%store train_ans_labbled \n",
    "%store devel_ans_labbled \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get head word \n",
    "def get_head_word(wh_word_index, full_postag):\n",
    "    head_word = ''\n",
    "    for token_id in range(wh_word_index, len(full_postag)):\n",
    "        pos = full_postag[token_id][1]\n",
    "        if pos == 'NN' or pos == 'NNS':\n",
    "            head_word = lmtzr.lemmatize(full_postag[token_id][0])\n",
    "            break\n",
    "    \n",
    "    if head_word == '':\n",
    "        for token_id in range(0, wh_word_index):\n",
    "            pos = full_postag[token_id][1]\n",
    "            if pos == 'NN' or pos == 'NNS':\n",
    "                head_word = lmtzr.lemmatize(full_postag[token_id][0])\n",
    "                break\n",
    "    return head_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features to conduct machine learning\n",
    "def get_data_feature(query_full_postag):\n",
    "    feature_list = []\n",
    "    wh_word = ''\n",
    "    wh_word_pos = ''\n",
    "    neigh_word = ''\n",
    "    neigh_word_pos = ''\n",
    "    head_word = ''\n",
    "    for token, pos in query_full_postag:\n",
    "        if pos == 'WDT' or pos == 'WP' or pos == 'WP$' or pos == 'WRB': \n",
    "            wh_word = token\n",
    "            wh_word_index = query_full_postag.index((token, pos))\n",
    "            wh_word_pos = query_full_postag[wh_word_index][1]\n",
    "            head_word = get_head_word(wh_word_index, query_full_postag)\n",
    "            if wh_word_index == len(query_full_postag) - 1:\n",
    "                neigh_word_index = ''\n",
    "                neigh_word = ''\n",
    "                neigh_word_pos = ''\n",
    "            else:\n",
    "                neigh_word_index = wh_word_index + 1\n",
    "                neigh_word = query_full_postag[neigh_word_index][0]\n",
    "                neigh_word_pos = query_full_postag[neigh_word_index][1]\n",
    "            break\n",
    "                        \n",
    "    if  wh_word == '':\n",
    "        wh_word = 'unk'\n",
    "        wh_word_pos = 'unk'\n",
    "        neigh_word = 'unk'\n",
    "        neigh_word_pos = 'unk'\n",
    "        head_word = get_head_word(0, query_full_postag)\n",
    "\n",
    "    feature_list = [wh_word, wh_word_pos, neigh_word, neigh_word_pos, head_word]\n",
    "    return feature_list\n",
    "    \n",
    "# train feature dict\n",
    "def get_train_features():\n",
    "    train_feature_dict = {}\n",
    "    for query_id in train_ans_labbled.keys():\n",
    "        if train_ans_labbled[query_id] != 'OTHER':\n",
    "            query_full_postag = train_query_full_postag[query_id]\n",
    "            train_feature_dict[query_id] = get_data_feature(query_full_postag)\n",
    "    return train_feature_dict\n",
    "\n",
    "def get_devel_features():\n",
    "    devel_feature_dict = {}\n",
    "    for query_id in devel_ans_labbled.keys():\n",
    "        query_full_postag = devel_query_full_postag[query_id]\n",
    "        devel_feature_dict[query_id] = get_data_feature(query_full_postag)\n",
    "    return devel_feature_dict\n",
    "\n",
    "def get_test_features():\n",
    "    test_feature_dict = {}\n",
    "    for query_id in range(len(test_query_full_postag)):\n",
    "        query_full_postag = test_query_full_postag[query_id]\n",
    "        test_feature_dict[query_id] = get_data_feature(query_full_postag)\n",
    "    return test_feature_dict\n",
    "    \n",
    "train_feature = get_train_features()\n",
    "devel_feature = get_devel_features()\n",
    "test_feature = get_test_features()\n",
    "\n",
    "%store train_feature \n",
    "%store devel_feature \n",
    "%store test_feature \n",
    "    \n",
    "# 33904 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "def get_BOW(feature_list):\n",
    "    BOW = {}\n",
    "    for token in feature_list:\n",
    "        BOW[token] = BOW.get(token, 0) + 1\n",
    "    return BOW\n",
    "\n",
    "def prepare_train_data(train_feature, feature_extractor):\n",
    "    feature_matrix = []\n",
    "    for query_id in train_feature.keys():\n",
    "        feature_list = train_feature[query_id]\n",
    "        feature_matrix.append(feature_extractor(feature_list))\n",
    "    return feature_matrix\n",
    "\n",
    "train_matrix = prepare_train_data(train_feature, get_BOW)\n",
    "devel_matrix = prepare_train_data(devel_feature, get_BOW)\n",
    "test_matrix = prepare_train_data(test_feature, get_BOW)\n",
    "\n",
    "def get_classification(features, ans_labbled):\n",
    "    classification = []\n",
    "    for query_id in features.keys():\n",
    "        classification.append(ans_labbled[query_id])\n",
    "    return classification\n",
    "\n",
    "train_classification = get_classification(train_feature, train_ans_labbled)\n",
    "devel_classification = get_classification(devel_feature, devel_ans_labbled)\n",
    "\n",
    "# transform data\n",
    "X_train = vectorizer.fit_transform(train_matrix)\n",
    "X_devel = vectorizer.transform(devel_matrix)\n",
    "X_test = vectorizer.transform(test_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def clf_NB_tune_parameters():\n",
    "    alphas = np.logspace(-2, 3, num = 100)\n",
    "    result = []\n",
    "    for alpha in alphas:\n",
    "        clf_NB = MultinomialNB(alpha = alpha)\n",
    "        clf_NB.fit(X_train, train_classification)\n",
    "        y_predict_NB = clf_NB.predict(X_devel)\n",
    "        accuracy = accuracy_score(devel_classification, y_predict_NB)\n",
    "        result.append([alpha, accuracy])\n",
    "    sorted_result = sorted(result, key = lambda tup: tup[1], reverse = True)\n",
    "    return sorted_result\n",
    "\n",
    "top_ten_NB_result = clf_NB_tune_parameters()[:10]\n",
    "best_alpha = top_ten_NB_result[0][0]\n",
    "\n",
    "def get_NB_predict(X_matric):\n",
    "    clf_NB = MultinomialNB(alpha = best_alpha)\n",
    "    clf_NB.fit(X_train, train_classification)\n",
    "    y_predict_NB = clf_NB.predict(X_matric)\n",
    "    return y_predict_NB \n",
    "\n",
    "NB_test_query_type = get_NB_predict(X_test)\n",
    "NB_devel_query_type = get_NB_predict(X_devel)\n",
    "\n",
    "'''\n",
    "0.7884615384615384 accuracy for NE type question\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "def clf_LR_tune_penalty(penalty):\n",
    "    clf_LR = LogisticRegression(penalty = penalty)\n",
    "    clf_LR.fit(X_train, train_classification)\n",
    "    y_predict_LR = clf_LR.predict(X_devel)\n",
    "    accuracy = accuracy_score(devel_classification, y_predict_LR)\n",
    "    return accuracy\n",
    "\n",
    "def clf_LR_tune_hyperparameter():\n",
    "    Cs = np.linspace(1e-2, 100, num = 200)\n",
    "    result = []\n",
    "    for C in Cs:\n",
    "        clf_LR = LogisticRegression(C = C)\n",
    "        clf_LR.fit(X_train, train_classification)\n",
    "        y_predict_LR = clf_LR.predict(X_devel)\n",
    "        accuracy = accuracy_score(devel_classification, y_predict_LR)\n",
    "        result.append([C, accuracy])\n",
    "    sorted_result = sorted(result, key = lambda tup: tup[1], reverse = True)\n",
    "    return sorted_result\n",
    "top_ten_LR_result = clf_LR_tune_hyperparameter()[:10]\n",
    "best_C = top_ten_LR_result[0][0]\n",
    "\n",
    "def get_LR_predict(X_matrix):\n",
    "    clf_LR = LogisticRegression(penalty = 'l2', C = 1.21)\n",
    "    clf_LR.fit(X_train, train_classification)\n",
    "    y_predict_LR = clf_LR.predict(X_matrix)\n",
    "    return y_predict_LR\n",
    "\n",
    "LR_test_query_type = get_LR_predict(X_test)\n",
    "LR_devel_query_type = get_LR_predict(X_devel)\n",
    "\n",
    "'''\n",
    "0.8028846153846154 accuracy for NE type question: Logistic Regression will be adopted \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 4. Answer ranking </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the candidate anwers\n",
    "def get_ans_candidate(dataset, data_set_ne, query_type, dataset_best_sent_ne_postag):\n",
    "    ans_candidate_dict = {}\n",
    "    answers = []\n",
    "    for query_id in range(len(dataset)):\n",
    "        ans_candidate = []\n",
    "        ans = ''\n",
    "        lowercased_query = dataset[query_id]['question'].lower()\n",
    "        # named entity for best match sentence\n",
    "        final_ne_sent = data_set_ne[query_id]\n",
    "        # query type\n",
    "        ans_type = query_type[query_id]\n",
    "        full_ne_postag = dataset_best_sent_ne_postag[query_id]\n",
    "        \n",
    "        # numeric question: complement stanford named entity\n",
    "        if 'far' in lowercased_query or 'many' in lowercased_query or 'much' in lowercased_query or 'long' in lowercased_query:\n",
    "            for token, pos in full_ne_postag:\n",
    "                if pos == 'CD':\n",
    "                    ans_candidate.append((token, pos, 1, 1))\n",
    "                  \n",
    "        if final_ne_sent == []:\n",
    "            for token_pair_id in range(len(full_ne_postag)):\n",
    "                token = full_ne_postag[token_pair_id][0]\n",
    "                pos = full_ne_postag[token_pair_id][1]\n",
    "                if pos == 'IN':\n",
    "                    next_token = full_ne_postag[token_pair_id + 1][0]\n",
    "                    next_pos = full_ne_postag[token_pair_id + 1][1]\n",
    "                    if next_token != 'the':\n",
    "                        if next_token not in lowercased_query:\n",
    "                            ans_candidate.append((next_token, next_pos, 1, 1))  \n",
    "                        else:\n",
    "                            ans_candidate.append((next_token, next_pos, 1, 2))\n",
    "        \n",
    "        if final_ne_sent == []:\n",
    "            ans_candidate = []   \n",
    "        else:\n",
    "            hi = []\n",
    "            low = []\n",
    "            for token, pos in final_ne_sent:\n",
    "                if token not in lowercased_query:\n",
    "                    if pos == ans_type:\n",
    "                        hi.append((token, pos, 1, 1)) # first integer: pos = ans_type; second integer: token not in query\n",
    "                    else:\n",
    "                        low.append((token, pos, 1, 2)) # if candidate token appear in the query, second integer = 2\n",
    "                else:\n",
    "                    low.append((token, pos, 2, 2))\n",
    "                      \n",
    "            ans_candidate.extend(hi)\n",
    "            ans_candidate.extend(low)\n",
    "            \n",
    "            if ans_candidate == []: \n",
    "                if ans_candidate == []:\n",
    "                    for token, pos in final_ne_sent:\n",
    "                        ans_candidate.append((token, pos, 1, 1))\n",
    "        ans_candidate_dict[query_id] = ans_candidate\n",
    "    return ans_candidate_dict\n",
    "\n",
    "test_ans_candidate = get_ans_candidate(testing_set, test_set_ne, LR_test_query_type, test_best_sent_ne_postag)\n",
    "devel_ans_candidate = get_ans_candidate(devel_set, devel_set_ne, LR_devel_query_type, devel_best_sent_ne_postag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance between NE or token and a NE from question if NEs are the same type\n",
    "# and rank all the candidate answers\n",
    "def get_distance_NE_in_query(dataset, ans_candidate_dict, dataset_best_sent_ne_postag, dataset_query_ne):\n",
    "    ans_submission = []\n",
    "    for query_id in ans_candidate_dict.keys():\n",
    "        query_ne_index_list = []\n",
    "        answers_index_list = []\n",
    "        ans_candidate = ans_candidate_dict[query_id] # candidate ans with postag and question type score\n",
    "        lowercased_query = dataset[query_id]['question'].lower()\n",
    "        \n",
    "        if ans_candidate != []:\n",
    "            ans_set = set(token for token, pos, question_type_score, token_in_query in ans_candidate) # remove replication \n",
    "            query_ne = dataset_query_ne[query_id] # NE of question\n",
    "            best_sent_token = [token for token, pos in dataset_best_sent_ne_postag[query_id]] # tokenize best matching sentence\n",
    "\n",
    "            answers_index_list = [] # candidate ans's index in the best matching sentence\n",
    "            for answers in ans_set:\n",
    "                ans_index = [i for i, j in enumerate(best_sent_token) if j == answers]\n",
    "                answers_index_list.append((answers, ans_index))\n",
    "\n",
    "            # find the index of query NE in the best matching sentence \n",
    "            if query_ne != []:\n",
    "                query_ne_index_list = [] # a list store the query NEs and their indexes\n",
    "                for token, ne_type in query_ne:\n",
    "                    if token in best_sent_token: # if query NE appears in best match sentence\n",
    "                        content_word_index = [i for i, j in enumerate(best_sent_token) if j == token] # query ne's index in sentence\n",
    "                        query_ne_index_list += content_word_index \n",
    "        \n",
    "        new_ans = []        \n",
    "        ans_candidate_new = {}    \n",
    "        # distance between sentence ne and query content word\n",
    "        if answers_index_list != [] and query_ne_index_list != []:\n",
    "            for answers, ans_index in answers_index_list:\n",
    "                distance = []\n",
    "                for ans_ne_index in ans_index:\n",
    "                    for query_ne_index in query_ne_index_list:\n",
    "                        distance.append(abs(ans_ne_index - query_ne_index))\n",
    "                min_distance = min(distance)\n",
    "                if answers not in lowercased_query:\n",
    "                    min_distance = min(distance)\n",
    "                else:\n",
    "                    min_distance = 1000\n",
    "                ans_candidate_new[answers] = min_distance\n",
    "            for token, pos, question_type_score, token_in_query in ans_candidate:\n",
    "                if token in ans_candidate_new.keys():\n",
    "                    new_ans.append((token, pos, question_type_score, token_in_query, ans_candidate_new[token]))\n",
    "                else:\n",
    "                    new_ans.append((token, pos, question_type_score, token_in_query, 1000))\n",
    "        else:\n",
    "            for token, pos, question_type_score, token_in_query in ans_candidate:\n",
    "                new_ans.append((token, pos, question_type_score, token_in_query, 1000))\n",
    "                \n",
    "        # rank all the answers\n",
    "        new_ans.sort(key=lambda x:(x[3],x[2],x[4]))\n",
    "        \n",
    "        if new_ans == []:\n",
    "            final_ans = ''\n",
    "        else:\n",
    "            final_ans = new_ans[0][0]\n",
    "        ans_submission.append((query_id, final_ans))\n",
    "    return ans_submission\n",
    "\n",
    "ans_devel_sub13 = get_distance_NE_in_query(devel_set, devel_ans_candidate, devel_best_sent_ne_postag, devel_query_ne)\n",
    "ans_test_sub13 = get_distance_NE_in_query(testing_set, test_ans_candidate, test_best_sent_ne_postag, test_query_ne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 5. Answer: output csv </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('test_ans13.csv', 'w', newline='', encoding='UTF-8') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    header = ['id', 'answer']\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(ans_test_sub13)\n",
    "csvfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 6. Measurement </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "ans_file = csv.reader(open('devel_ans13.csv', 'r'))\n",
    "ans_dict = {}\n",
    "for item in ans_file:\n",
    "    if ans_file.line_num == 1:\n",
    "        continue\n",
    "    ans_dict[int(item[0])] = item[1]\n",
    "\n",
    "def average_f1_score(ans_dict):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for ans_id in ans_dict.keys():\n",
    "        my_ans = word_tokenize(re.sub(r'[^\\w\\s]', '', ans_dict[ans_id].lower())) # remove punctuations\n",
    "        gold_ans = devel_set[ans_id]['text']\n",
    "        gold_ans = word_tokenize(re.sub(r'[^\\w\\s]', '', gold_ans.lower()))\n",
    "        for token in my_ans:\n",
    "            if token in gold_ans:\n",
    "                TP += 1\n",
    "            elif token not in gold_ans:\n",
    "                FP += 1\n",
    "        for gold_token in gold_ans:\n",
    "            if gold_token not in my_ans:\n",
    "                FN += 1\n",
    "    recall = TP/(TP + FN)\n",
    "    prec = TP/(TP + FP)\n",
    "    average_f1_score = 2 * (recall * prec)/(recall + prec)\n",
    "    return average_f1_score\n",
    "\n",
    "final_QA_f1 = average_f1_score(ans_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
